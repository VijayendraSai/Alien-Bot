{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzcR5RHimvmF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ast\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from google.colab import drive\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTER PATH TO THE DATA\n",
        "data = pd.read_excel(\"/content/drive/MyDrive/AI-Project-3/model1_data_final.xlsx\")\n",
        "\n",
        "ship = data['ship']\n",
        "alien_prob = data['beliefNetworkAlien']\n",
        "crew_prob = data['beliefNetworkCrew']\n",
        "bot = data['bot_cell']\n",
        "alien_beep = data[\"isBeepAlien\"]\n",
        "crew_beep = data[\"isBeepCrew\"]\n",
        "\n",
        "move = data[\"move\"].tolist()"
      ],
      "metadata": {
        "id": "luCcP7LpmzUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data size: \", len(data))\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "\n",
        "for i in range(len(data)-1):\n",
        "  a = ast.literal_eval(ship[i])\n",
        "  b = list(ast.literal_eval(alien_prob[i][1:-1]))\n",
        "  c = list(ast.literal_eval(crew_prob[i][1:-1]))\n",
        "  d = ast.literal_eval(bot[i])\n",
        "  e = [float(alien_beep[i])]\n",
        "  f = [float(crew_beep[i])]\n",
        "\n",
        "  X_train.append(a+b+c+d+e+f)\n",
        "  y_train.append(float(move[i]))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "y_train_cat = to_categorical(y_train, num_classes=4)\n"
      ],
      "metadata": {
        "id": "ZoJOXUJnm07w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_train_actor = 0\n",
        "end_train_actor=5000\n",
        "\n",
        "start_test_actor = -2000\n",
        "end_test_actor = -1000\n",
        "\n",
        "start_train_critic = 0\n",
        "end_train_critic = 5000\n",
        "\n",
        "start_test_critic = -2000\n",
        "end_test_critic = -1000\n",
        "\n",
        "critic_accuracy = []\n",
        "actor_accuracy = []"
      ],
      "metadata": {
        "id": "24RHW9Slm26n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTOR-CRITIC Loop"
      ],
      "metadata": {
        "id": "jV_2cn7GnD0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  # X_train for Actor (X_pred for Critic)\n",
        "  x_temp_train = X_train[start_train_actor:end_train_actor, :-2]\n",
        "  X_train_actor = x_temp_train\n",
        "\n",
        "  #X_test for Actor\n",
        "  X_temp_test = X_train[start_test_actor:end_test_actor, :-2]\n",
        "  X_test_actor = X_temp_test\n",
        "  y_test = y_train[start_test_actor:end_test_actor]\n",
        "\n",
        "\n",
        "  # Train data for Critic\n",
        "  #ENTER PATH TO DATA\n",
        "  X_train_temp2 = np.load(\"/content/drive/MyDrive/AI-Project-3/X_train150.npy\")\n",
        "  y_train_temp2 = np.load(\"/content/drive/MyDrive/AI-Project-3/y_train150.npy\")\n",
        "\n",
        "  #Slicing for epochs\n",
        "  X_train_critic = X_train_temp2[start_train_critic:end_train_critic]\n",
        "  X_test_critic = X_train_temp2[start_test_critic:end_test_critic]\n",
        "  y_train_critic = y_train_temp2[start_train_critic:end_train_critic]\n",
        "  y_test_critic = y_train_temp2[start_test_critic:end_test_critic]\n",
        "\n",
        "\n",
        "  # Train the Critic model\n",
        "  inp_size = X_train_critic.shape[1]\n",
        "  # Create a logistic regression model\n",
        "  critic_model = RandomForestClassifier(warm_start=True)\n",
        "  critic_model.fit(X_train_critic[:, :inp_size], y_train_critic)\n",
        "  # Prediction from Critic\n",
        "  # Predict probabilities for class 1\n",
        "  probabilities = critic_model.predict_proba(X_test_critic[:,:inp_size])[:, 1]\n",
        "\n",
        "  pred = []\n",
        "  for i in range(len(probabilities)):\n",
        "    if probabilities[i]>= 0.5:\n",
        "      pred.append(1)\n",
        "    else:\n",
        "      pred.append(0)\n",
        "\n",
        "  c_accuracy = accuracy_score(y_test_critic, np.array(pred))\n",
        "  critic_accuracy.append(c_accuracy)\n",
        "  print(\"Critic Accuracy: \",c_accuracy)\n",
        "\n",
        "\n",
        "  #Training data prediction loop\n",
        "  preds = {}\n",
        "  for i in range(0,4):\n",
        "    move = np.full((len(x_temp_train), 1), i)\n",
        "    X_input_critic = np.hstack((x_temp_train, move))\n",
        "    preds[i] = list(critic_model.predict_proba(X_input_critic[:,:inp_size])[:, 1])\n",
        "\n",
        "\n",
        "  # Training truth for Actor\n",
        "  y_train_actor = []\n",
        "  for i in range(len(X_input_critic)):\n",
        "    temp = [preds[0][i], preds[1][i], preds[2][i], preds[3][i]]\n",
        "\n",
        "    ans = temp.index(max(temp))\n",
        "    y_train_actor.append(ans)\n",
        "  y_train_actor = np.array(y_train_actor)\n",
        "\n",
        "\n",
        "  # ACTOR\n",
        "  inp_size2 = X_train_actor.shape[1]\n",
        "\n",
        "  actor_model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000, warm_start=True)\n",
        "  # Train the model on the training data\n",
        "  actor_model.fit(X_train_actor[:,:inp_size2], y_train_actor)\n",
        "  train_predictions = actor_model.predict(X_train_actor[:,:inp_size2])\n",
        "  train_accuracy = accuracy_score(y_train_actor, train_predictions)\n",
        "  print(f\"Actor Accuracy (Train): {train_accuracy:.4f}\")\n",
        "\n",
        "  # Convert one-hot encoded predictions back to categorical labels\n",
        "  y_pred = actor_model.predict(X_test_actor[:,:inp_size2])\n",
        "\n",
        "  # Evaluate the model\n",
        "  a_accuracy = accuracy_score(y_test, to_categorical(y_pred, num_classes=4))\n",
        "  actor_accuracy.append(a_accuracy)\n",
        "  print(f\"Actor Accuracy (Test): {a_accuracy:.4f}\")\n",
        "\n",
        "  start_train_actor = end_train_actor\n",
        "  end_train_actor += 5000\n",
        "\n",
        "  start_train_critic += 1000\n",
        "  end_train_critic += 1000\n",
        "\n",
        "  end_test_actor = start_test_actor\n",
        "  start_test_actor -= 1000\n",
        "\n",
        "  end_test_critic = start_test_critic\n",
        "  start_test_critic -= 1000"
      ],
      "metadata": {
        "id": "StgBBb98m6IH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}